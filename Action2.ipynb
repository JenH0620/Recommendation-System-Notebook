{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTofg9pmkNrTEzlDp38zWo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JenH0620/Recommendation-System-Notebook/blob/Ch3.2-svd/Action2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0St9eiU8tZtd",
        "colab_type": "code",
        "outputId": "df1abf29-ba29-4e3b-8cfd-0f97a4c2f576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#!pip install deepctr\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.inputs import SparseFeat,get_feature_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepctr in /usr/local/lib/python3.6/dist-packages (0.7.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from deepctr) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from deepctr) (2.8.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->deepctr) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py->deepctr) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iksH8lMNtmjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##DeepFM\n",
        "data = pd.read_csv(\"ratings.csv\")\n",
        "sparse_features = [\"userId\", \"movieId\", 'timestamp']\n",
        "target = ['rating']\n",
        "\n",
        "# 对特征标签进行编码\n",
        "for feature in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feature] = lbe.fit_transform(data[feature])\n",
        "# 计算每个特征中的 不同特征值的个数\n",
        "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique()) for feature in sparse_features]\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "# 将数据集切分成训练集和测试集\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train_model_input = {name:train[name].values for name in feature_names}\n",
        "test_model_input = {name:test[name].values for name in feature_names}\n",
        "\n",
        "# 使用DeepFM进行训练\n",
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=10, verbose=True, validation_split=0.2, )\n",
        "# 使用DeepFM进行预测\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "# 输出RMSE或MSE\n",
        "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
        "rmse = mse ** 0.5\n",
        "print(\"test RMSE\", rmse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkvt5jEWdbkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install surprise\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import KFold\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkUtS2jO67So",
        "colab_type": "code",
        "outputId": "b281762f-e6dd-4936-e611-7ea72927b764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# 使用funkSVD\n",
        "time1=time.time()\n",
        "\n",
        "# 数据读取\n",
        "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "data = Dataset.load_from_file('ratings.csv', reader=reader)\n",
        "train_set = data.build_full_trainset()\n",
        "\n",
        "# 使用funkSVD\n",
        "algo = SVD(biased=False)\n",
        "\n",
        "# 定义K折交叉验证迭代器，K=3\n",
        "kf = KFold(n_splits=3)\n",
        "for trainset, testset in kf.split(data):\n",
        "    # 训练并预测\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "    # 计算RMSE\n",
        "    accuracy.rmse(predictions, verbose=True)\n",
        "\n",
        "uid = str(196)\n",
        "iid = str(302)\n",
        "# 输出uid对iid的预测结果\n",
        "pred = algo.predict(uid, iid, r_ui=4, verbose=True)\n",
        "time2=time.time()\n",
        "print(time2-time1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: surprise in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.6/dist-packages (from surprise) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.14.1)\n",
            "RMSE: 0.8728\n",
            "RMSE: 0.8735\n",
            "RMSE: 0.8726\n",
            "user: 196        item: 302        r_ui = 4.00   est = 4.28   {'was_impossible': False}\n",
            "164.97616720199585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODtqsQeASCdU",
        "colab_type": "code",
        "outputId": "86c9e632-1c1d-4626-9fbe-27595bcdb942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# 使用biasSVD\n",
        "time1=time.time()\n",
        "\n",
        "# 数据读取\n",
        "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "data = Dataset.load_from_file('ratings.csv', reader=reader)\n",
        "train_set = data.build_full_trainset()\n",
        "\n",
        "# 使用biasSVD\n",
        "algo = SVD(biased=True)\n",
        "\n",
        "# 定义K折交叉验证迭代器，K=3\n",
        "kf = KFold(n_splits=3)\n",
        "for trainset, testset in kf.split(data):\n",
        "    # 训练并预测\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "    # 计算RMSE\n",
        "    accuracy.rmse(predictions, verbose=True)\n",
        "\n",
        "uid = str(196)\n",
        "iid = str(302)\n",
        "# 输出uid对iid的预测结果\n",
        "pred = algo.predict(uid, iid, r_ui=4, verbose=True)\n",
        "time2=time.time()\n",
        "print(time2-time1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.8451\n",
            "RMSE: 0.8451\n",
            "RMSE: 0.8452\n",
            "user: 196        item: 302        r_ui = 4.00   est = 4.17   {'was_impossible': False}\n",
            "171.23549818992615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK0lwSgKGmLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 使用SVD++\n",
        "#!pip install surprise\n",
        "from surprise import SVDpp\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import KFold\n",
        "import pandas as pd\n",
        "\n",
        "# 数据读取\n",
        "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "data = Dataset.load_from_file('ratings.csv', reader=reader)\n",
        "train_set = data.build_full_trainset()\n",
        "\n",
        "# 使用biasSVD\n",
        "algo = SVDpp(n_epochs=20)\n",
        "\n",
        "# 定义K折交叉验证迭代器，K=3\n",
        "kf = KFold(n_splits=3)\n",
        "for trainset, testset in kf.split(data):\n",
        "    # 训练并预测\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "    # 计算RMSE\n",
        "    accuracy.rmse(predictions, verbose=True)\n",
        "\n",
        "uid = str(196)\n",
        "iid = str(302)\n",
        "# 输出uid对iid的预测结果\n",
        "pred = algo.predict(uid, iid, r_ui=4, verbose=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsUTYjXcCqCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Without surprise ---- spark mllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZknEU3_ZgCVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f98bea6f-5ab1-4b7a-e2f2-9e552eb3103a"
      },
      "source": [
        "##Without surprise ---- LightFM\n",
        "#!pip install lightfm\n",
        "import numpy as np\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from lightfm import LightFM\n",
        "from lightfm import cross_validation\n",
        "import pandas as pd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.6/dist-packages (1.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from lightfm) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ6qpX14Ryhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "4cd47f2b-0761-48e8-8eda-7aacc8d387d8"
      },
      "source": [
        "##This is from the CSDN blog: https://blog.csdn.net/m0_37586991/article/details/79943400\n",
        "# fetch data and format it\n",
        "data = fetch_movielens(min_rating=4.0)  # only collect the movies with a rating of 4 or higher\n",
        " \n",
        "# print training and testing data\n",
        "print(repr(data['train']))\n",
        "print(repr(data['test']))\n",
        "'''repr()函数将对象转化为供解释器读取的形式'''\n",
        " \n",
        "# create model\n",
        "model = LightFM(loss='warp')  # warp = weighted approximate-rank pairwise\n",
        "'''\n",
        "warp helps us create recommendations for each user by looking at the existing user rating pairs\n",
        "and predicting rankings for each, it uses the gradient descent algorithm to iteratively find the\n",
        "weights that improve our prediction over time. This takes into account both the user's past rating\n",
        "history content based and similar user ratings collaborative, it's a hybrid system.\n",
        "WARP is an implicit feedback model: all interactions in the training matrix are treated as positive \n",
        "signals, and products that users did not interact with they implicitly do not like. The goal of the \n",
        "model is to score these implicit positives highly while assigning low scores to implicit negatives.\n",
        "'''\n",
        "# train model\n",
        "model.fit(data['train'], epochs=30, num_threads=2)\n",
        "'''\n",
        "parameters: the data set we want to train it on,\n",
        "            the number of epochs we want to run the training for,\n",
        "            the number of threads we want to run this on\n",
        "Model training is accomplished via SGD (stochastic gradient descent). This means that for every pass through \n",
        "the data — an epoch — the model learns to fit the data more and more closely. We’ll run it for 10 epochs in \n",
        "this example. We can also run it on multiple cores, so we’ll set that to 2. (The dataset in this example is \n",
        "too small for that to make a difference, but it will matter on bigger datasets.)\n",
        "'''\n",
        " \n",
        "def sample_recommendation(model, data, user_ids):\n",
        "    # our model, our data and a list of user ids(these are users we want to generate recommendations for)\n",
        " \n",
        "    # number of users and movies in training data\n",
        "    n_users, n_items = data['train'].shape\n",
        " \n",
        "    # generate recommendation for each user we input\n",
        "    '''\n",
        "    iterate through every user id that we input and say that we want the list of known positives for each line\n",
        "    if M considers ratings that are 5 positive and ratings that are 4 or below negative to make the problem binary \n",
        "    much simplers\n",
        "    '''\n",
        "    for user_id in user_ids:\n",
        " \n",
        "        # movies they already like\n",
        "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
        "        '''\n",
        "        data['item_labels']的类型是  <class 'numpy.ndarray'>\n",
        "        data['train']的类型是  <class 'scipy.sparse.coo.coo_matrix'> 即 坐标形式的一种稀疏矩阵\n",
        "            # tocsr() 的作用是  Return a copy of this matrix in Compressed Sparse Row format\n",
        "            # coo_matrix.tocsr() 将把coo_matrix转化为csr_matrix，所以，\n",
        "        data['train'].tocsr()的类型是 <class 'scipy.sparse.csr.csr_matrix'> 即 压缩的行稀疏矩阵\n",
        "        data['train'].tocsr()[user_id] 的类型也是 <class 'scipy.sparse.csr.csr_matrix'>\n",
        "        data['train'].tocsr()[user_id].indices 的类型是 <class 'numpy.ndarray'>\n",
        "            # indices属性的作用是返回\tCSR format index array of the matrix\n",
        "            \n",
        "        总之，data['train'].tocsr()[2].indices 获取  user_id=2 的观众打分为5的电影索引数组\n",
        "        data['item_labels'][...]  根据索引数组，输出对应的电影名称\n",
        "        \n",
        "        '''\n",
        "        # movies our model predicts they will like\n",
        "        scores = model.predict(user_id, np.arange(n_items))\n",
        "        '''np.arange()用于创建等差数组，返回一个array对象'''\n",
        "        # rank them in order of most liked to least\n",
        "        top_items = data['item_labels'][np.argsort(-scores)]\n",
        "        '''np.argsort(x)返回数组值从小到大的索引值,np.argsort(-x)按降序排列'''\n",
        " \n",
        "        # print out the results\n",
        "        print(\"User %s\" % user_id)\n",
        "        print(\"      Known positives:\")\n",
        " \n",
        "        for x in known_positives[:3]:\n",
        "            print(\"         %s\" % x)\n",
        "        print(\"      Recommended:\")\n",
        "        for x in top_items[:3]:\n",
        "            print(\"         %s\" % x)\n",
        " \n",
        " \n",
        "sample_recommendation(model, data, [3,25,450])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 49906 stored elements in COOrdinate format>\n",
            "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 5469 stored elements in COOrdinate format>\n",
            "User 3\n",
            "      Known positives:\n",
            "         Seven (Se7en) (1995)\n",
            "         Contact (1997)\n",
            "         Starship Troopers (1997)\n",
            "      Recommended:\n",
            "         Scream (1996)\n",
            "         Contact (1997)\n",
            "         Devil's Own, The (1997)\n",
            "User 25\n",
            "      Known positives:\n",
            "         Dead Man Walking (1995)\n",
            "         Star Wars (1977)\n",
            "         Fargo (1996)\n",
            "      Recommended:\n",
            "         English Patient, The (1996)\n",
            "         Titanic (1997)\n",
            "         Fargo (1996)\n",
            "User 450\n",
            "      Known positives:\n",
            "         Contact (1997)\n",
            "         George of the Jungle (1997)\n",
            "         Event Horizon (1997)\n",
            "      Recommended:\n",
            "         Devil's Advocate, The (1997)\n",
            "         Devil's Own, The (1997)\n",
            "         Dante's Peak (1997)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD7wFA3pRy8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Without surprise ---- https://github.com/tushushu/imylu/blob/master/imylu/recommend/als.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}